"""
Streamlit app: Fungi Classifier + Multiâ€‘XAI Dashboard
----------------------------------------------------
* Classifies 48 mushroom species (ResNet50 backbone stored on Dropbox)
* Explanation methods selectable in sidebar:
  â€“ Gradâ€‘CAM (baseline)
  â€“ Gradâ€‘CAM++
  â€“ Integrated Gradients
  â€“ Occlusion Sensitivity
* Extra XAI text
* UX extras: TOPâ€‘k barâ€‘chart, full confidence table, heatâ€‘map alpha slider, species facts, safety banner, logging CSV
* Professorâ€‘mode flags: simulate misclassification, switch backbone (future)

Install missing packages:
    pip install streamlit tensorflow tf-keras-vis pillow numpy opencv-python
"""

from __future__ import annotations
import csv
import datetime as _dt
import os
import pathlib
import requests

import cv2
import numpy as np
import tensorflow as tf
from PIL import Image
import streamlit as st

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ PAGE CONFIG (must be first st.* call)
st.set_page_config(page_title="Fungi Classifier XAI", page_icon="ğŸ„", layout="centered")

# Optional XAI libs (Gradâ€‘CAM++, Integrated Gradients)
try:
    from tf_keras_vis.gradcam import Gradcam
    from tf_keras_vis.gradcam_plus_plus import GradcamPlusPlus
    from tf_keras_vis.integrated_gradients import IntegratedGradients
    from tf_keras_vis.utils.scores import CategoricalScore
    _XAI_OK = True
except ModuleNotFoundError:
    _XAI_OK = False

########################################################################
# 1. DATA & MODELS #####################################################
########################################################################
_MODEL_URL = (
    "https://www.dropbox.com/scl/fi/437k0jr5hvzzyfyrp50z2/"
    "fungi_classifier_model.h5?rlkey=2tar5m1btexq24y6cf2inosnf&dl=1"
)
_MODEL_PATH = "fungi_classifier_model.h5"
_LABEL_PATH = "class_labels.txt"
_LOG_PATH = "predictions_log.csv"

@st.cache_resource(show_spinner=True, ttl=60 * 60 * 24)
def load_model() -> tf.keras.Model:  # noqa: N802
    """Download (if necessary) and cache Keras model."""
    if not os.path.isfile(_MODEL_PATH):
        with st.spinner("ğŸ“¥ Scaricamento modello (~80â€¯MB)â€¦"):
            r = requests.get(_MODEL_URL, stream=True, timeout=60)
            r.raise_for_status()
            with open(_MODEL_PATH, "wb") as f:
                for chunk in r.iter_content(8192):
                    f.write(chunk)
    return tf.keras.models.load_model(_MODEL_PATH, compile=False)

@st.cache_resource
def load_labels() -> list[str]:
    with open(_LABEL_PATH, encoding="utf-8") as f:
        return [ln.strip() for ln in f]

model = load_model()
SPECIES = load_labels()
NUM_CLASSES = len(SPECIES)

# â”€â”€ Extra metadata: Italian name & edibility â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
FUNGI_INFO: dict[str, dict[str, str]] = {
    "Agaricus bisporus": {"it": "Prataiolo coltivato", "edible": "Commestibile"},
    "Agaricus subrufescens": {"it": "Prataiolo mandorlato", "edible": "Commestibile"},
    "Amanita bisporigera": {"it": "Amanita bisporigera", "edible": "Velenoso"},
    "Amanita muscaria": {"it": "Amanita muscaria", "edible": "Velenoso"},
    "Amanita ocreata": {"it": "Amanita ocreata", "edible": "Velenoso"},
    "Amanita phalloides": {"it": "Amanita falloide", "edible": "Mortale"},
    "Amanita smithiana": {"it": "Amanita smithiana", "edible": "Velenoso"},
    "Amanita verna": {"it": "Amanita verna", "edible": "Mortale"},
    "Amanita virosa": {"it": "Amanita virosa", "edible": "Mortale"},
    "Auricularia auricula-judae": {"it": "Orecchio di Giuda", "edible": "Commestibile"},
    "Boletus edulis": {"it": "Porcino", "edible": "Commestibile"},
    # â€¦ (truncated for brevity â€“ include all 48 entries as in original)
}

########################################################################
# 2. PRE/POSTâ€‘PROCESSING ###############################################
########################################################################

def preprocess(img: Image.Image) -> np.ndarray:
    """Resizeâ†’normâ†’shape (1,128,128,3)."""
    arr = cv2.resize(np.array(img.convert("RGB")), (128, 128)) / 255.0
    return arr[np.newaxis, ...].astype("float32")


def predict(img_arr: np.ndarray) -> tuple[str, float, np.ndarray]:
    preds = model.predict(img_arr, verbose=0)[0]
    idx = int(np.argmax(preds))
    return SPECIES[idx], float(preds[idx]), preds

########################################################################
# 3. XAI UTILITIES #####################################################
########################################################################

def _norm(hm: np.ndarray) -> np.ndarray:
    hm = np.maximum(hm, 0)
    hm = hm / hm.max() if hm.max() else hm
    return cv2.resize(hm, (128, 128))


def gradcam_hm(arr: np.ndarray, idx: int) -> np.ndarray:
    if not _XAI_OK:
        st.error("Installa tfâ€‘kerasâ€‘vis per Gradâ€‘CAM")
        return np.zeros((128, 128))
    score = CategoricalScore([idx])
    cam = Gradcam(model)
    return _norm(cam(score, arr)[0])


def gradcampp_hm(arr: np.ndarray, idx: int) -> np.ndarray:
    if not _XAI_OK:
        st.error("Gradâ€‘CAM++ richiede tfâ€‘kerasâ€‘vis")
        return np.zeros((128, 128))
    score = CategoricalScore([idx])
    campp = GradcamPlusPlus(model)
    return _norm(campp(score, arr)[0])


def integgrads_hm(arr: np.ndarray, idx: int) -> np.ndarray:
    if not _XAI_OK:
        st.error("Integrated Gradients richiede tfâ€‘kerasâ€‘vis")
        return np.zeros((128, 128))
    score = CategoricalScore([idx])
    ig = IntegratedGradients(model)
    attr = ig(score, arr, steps=24)[0].mean(-1)
    return _norm(attr)


def occlusion_hm(img: Image.Image, patch: int, stride: int, idx: int) -> np.ndarray:
    base = cv2.resize(np.array(img.convert("RGB")), (128, 128))
    h, w, _ = base.shape
    base_prob = model.predict(base[np.newaxis] / 255.0, verbose=0)[0][idx]
    heat = np.zeros((h, w), dtype="float32")
    for y in range(0, h, stride):
        for x in range(0, w, stride):
            occl = base.copy()
            occl[y:y + patch, x:x + patch] = 0
            p = model.predict(occl[np.newaxis] / 255.0, verbose=0)[0][idx]
            heat[y:y + patch, x:x + patch] = base_prob - p
    return _norm(heat)


def overlay(img: Image.Image, hm: np.ndarray, alpha: float) -> np.ndarray:
    rgb = cv2.resize(np.array(img.convert("RGB")), (128, 128))
    cmap = cv2.applyColorMap(np.uint8(hm * 255), cv2.COLORMAP_JET)
    return cv2.addWeighted(cmap, alpha, rgb, 1 - alpha, 0)

########################################################################
# 4. UI ###############################################################
########################################################################

st.title("ğŸ„ Classificatore di Funghi con Explainability")
st.info("âš ï¸ **Non consumare funghi basandoti solo su questo modello** â€” puÃ² sbagliare!")

with st.sidebar:
    st.header("ğŸ”§ Parametri")
    method = st.selectbox(
        "Metodo di spiegazione",
        ["Gradâ€‘CAM", "Gradâ€‘CAM++", "Integrated Gradients", "Occlusion Sensitivity"],
    )
    alpha = st.slider("Trasparenza heatâ€‘map", 0.1, 0.8, 0.4, 0.05)
    if method == "Occlusion Sensitivity":
        patch = st.slider("Dimensione patch", 4, 32, 16, 2)
        stride = st.slider("Stride", 4, 32, 8, 2)
    else:
        patch = stride = None
    topk = st.slider("Mostra TOPâ€‘k specie", 3, 15, 5)
    show_all_conf = st.checkbox("Mostra tabella confidenze")
    simulate_err = st.checkbox("Simula misclassificazione (20â€¯%)")

uploaded = st.file_uploader("Carica foto del fungo", ["jpg", "jpeg", "png"])
if not uploaded:
    st.caption("â¬†ï¸ Carica un'immagine per iniziareâ€¦")
    st.stop()

img = Image.open(uploaded)
st.image(img, caption="ğŸ“· Immagine caricata", use_column_width=True)
arr = preprocess(img)
label, conf, preds = predict(arr)
if simulate_err and np.random.rand() < 0.2:
    alt_idx = int(np.argsort(preds)[-2])
    label, conf = SPECIES[alt_idx], float(preds[alt_idx])

info = FUNGI_INFO.get(label, {"it": "â€”", "edible": "â€”"})

st.subheader("ğŸ” Risultato")
st.markdown(f"**Specie predetta:** `{label}`  ")
st.markdown(f"**Nome italiano:** {info['it']}  ")
st.markdown(f"**CommestibilitÃ :** {info['edible']}  ")
st.markdown(f"**Confidenza:** `{conf*100:.1f}%`")

# TOPâ€‘k bar chart
idx_sorted = np.argsort(preds)[::-1][:topk]
st.bar_chart({SPECIES[i]: float(preds[i]) for i in idx_sorted})

# Full confidences
if show_all_conf:
    st.expander("Tabella confidenze per tutte le classi", expanded=False).dataframe(
        {"Specie": SPECIES, "ProbabilitÃ ": preds}, use_container_width=True
    )

# Heatâ€‘map
pred_idx = int(np.argmax(preds))
if method == "Gradâ€‘CAM":
    hm = gradcam_hm(arr, pred_idx)
elif method == "Gradâ€‘CAM++":
    hm = gradcampp_hm(arr, pred_idx)
elif method == "Integrated Gradients":
    hm = integgrads_hm(arr, pred_idx)
else:
    hm = occlusion_hm(img, patch or
